---
title: "Trend features"
---

```{r set_up_python, echo=FALSE}
#|echo: FALSE

if (Sys.getenv("USERPROFILE") == "C:\\Users\\internet"){
  
  python_path = paste0("C:\\Users\\internet\\AppData\\Local",
                       "\\Programs\\Python\\Python312\\python.exe")
} else {
  
  python_path = paste0("C:\\Users\\Home\\AppData\\Local",
                       "\\Programs\\Python\\Python312\\python.exe")
}

reticulate::use_python(python_path)

```

```{python load_libraries}

import numpy as np

import pandas as pd

import matplotlib.pyplot as plt

import seaborn as sns

import os 

from sklearn.linear_model import LinearRegression

from sklearn.tree import DecisionTreeRegressor

from sklearn.ensemble import HistGradientBoostingRegressor

from sklearn.metrics import root_mean_squared_error
```

```{python import_data}

file_path = os.path.expanduser("~/Documents") + "\\DS_advanced_website\\data\\example_air_passengers.csv"

raw_df = pd.read_csv(file_path,index_col = "date")

raw_df.index = pd.to_datetime(raw_df.index)


```

## Split data and auxiliary functions

```{python split_train_test_data}

raw_df["trend"] = (raw_df.index - raw_df.index.min()).days.astype(float)

split_date = pd.to_datetime("1960-01-01")


X_train = raw_df[["trend"]].loc[raw_df.index <= split_date]

X_test = raw_df[["trend"]].loc[raw_df.index > split_date]

y_train = raw_df["passengers"].loc[raw_df.index <= split_date]

y_test = raw_df["passengers"].loc[raw_df.index > split_date]


```


```{python plot_function}

def plot_pred(df,pred_train, pred_test):
  
  plot_df = df.copy()
  
  plot_df["pred"] = np.concatenate([pred_train, pred_test])
  
  plot_df["type"] = np.concatenate([["train"] * len(pred_train),
                                    ["test"] * len(pred_test)])
  
  rmse_by_group = plot_df.groupby('type').apply(
    lambda grouped_df: root_mean_squared_error(grouped_df["passengers"],grouped_df["pred"]),
    include_groups=False)
    
  # Add RMSE annotations
  
  train_mid_date = plot_df.index[len(pred_train) // 3]
  
  test_mid_date = plot_df.index[int(np.ceil(len(pred_train) * 0.7))]
  
  plot_df_wide = plot_df.reset_index().copy()

  plot_df_wide = plot_df_wide.melt(id_vars = ["type", "date"],
                         value_vars = ["passengers","pred"],
                         var_name = "line_type").copy()
                         
  plt.clf()
                         
  sns.lineplot(data=plot_df_wide, x="date",
               y="value", hue="type", style="line_type", legend = False,
             palette={"train": "blue", "test": "red"})
               
  plt.text(train_mid_date, plot_df["passengers"].loc[train_mid_date] * 2,
  f"RMSE = {rmse_by_group.loc['train']:.2f}",color='blue', fontsize=10)
  
  plt.text(test_mid_date, max(plot_df["passengers"]) * 0.95,
  f"RMSE = {rmse_by_group.loc['test']:.2f}", color='red', fontsize=10)

 

  plt.show()


```


# Linear trend

++ explain the we will introduce a linear trend (by using time feature) and then
we'll see how different models (linear regression and tree based models such as decision tree and gradient boosting) work with this feature. It turns out that tree based model have difficulties with handling trends (and linear trends in particular) 

## Linear model

```{python lin_reg_pred}

lin_reg = LinearRegression()

lin_reg.fit(X_train, y_train)

y_pred_train_lin_reg = lin_reg.predict(X_train)

y_pred_test_lin_reg = lin_reg.predict(X_test)


```

```{python plot_line_reg}

plot_pred(df = raw_df.copy(), pred_train = y_pred_train_lin_reg,
          pred_test = y_pred_test_lin_reg)


```

## Tree model

++ explain that tree based models are giving one prediction in the final leave and that results in missing the trend and not being able to extrapolate the linear trend (based on time feature)

```{python tree_model}

tree_model = DecisionTreeRegressor(max_depth = 1)

tree_model.fit(X_train, y_train)

y_pred_train_tree = tree_model.predict(X_train)

y_pred_test_tree = tree_model.predict(X_test)


```


```{python plot_tree}

plot_pred(df = raw_df.copy(), pred_train = y_pred_train_tree,
          pred_test = y_pred_test_tree)


```


## Gradient boosting

++ explain that the gradient boosting is a more flexible model than decision tree but it still fails to deal with linear trend because the nature of the problem (tree based models giving one prediction in the final leave) is the same

```{python gb_model}

gb_model = HistGradientBoostingRegressor()

gb_model.fit(X_train, y_train)

y_pred_train_gb = gb_model.predict(X_train)

y_pred_test_gb = gb_model.predict(X_test)

```


```{python plot_gb}

plot_pred(df = raw_df.copy(), pred_train = y_pred_train_gb,
          pred_test = y_pred_test_gb)


```



## Rolling forecast

```{python}

forecast_start = raw_df.index[-1] + pd.DateOffset(months = 1)

forecast_df = pd.DataFrame(index = pd.date_range(start = forecast_start,
                                                 periods = 12,
                                                 freq = "MS"))

```




# Change points


## Nonlinear trend

++explain that we add a square term in order to capture the non linear trend component. Emphasize that extrapolating non linear terms can often result overfitting and unreal forecasts

```{python lin_reg_pred_square}

X_train_square = X_train.copy()

X_train_square["trend_sq"] = X_train_square ** 2

X_test_square = X_test.copy()

X_test_square["trend_sq"] = X_test_square ** 2

lin_reg = LinearRegression()

lin_reg.fit(X_train_square, y_train)

y_pred_train_lin_reg_square = lin_reg.predict(X_train_square)

y_pred_test_lin_reg_square = lin_reg.predict(X_test_square)


```

```{python plot_line_reg_square}

plot_pred(df = raw_df.copy(), pred_train = y_pred_train_lin_reg_square,
          pred_test = y_pred_test_lin_reg_square)


```


# Evaluation

```{python }

rmse_test_lin = root_mean_squared_error(y_pred_test_lin_reg, y_test)

rmse_test_square = root_mean_squared_error(y_pred_test_lin_reg_square, y_test)

print(f"The rmse for the test set of the linear model is {np.round(rmse_test_lin,2)} and the square term is {np.round(rmse_test_square,2)}")

```

## Regularization