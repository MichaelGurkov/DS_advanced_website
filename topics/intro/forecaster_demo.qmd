---
title: "Forecasting demonstration"
---

```{r set_up_python, echo=FALSE}
#|echo: FALSE

if (Sys.getenv("USERPROFILE") == "C:\\Users\\internet"){
  
  python_path = paste0("C:\\Users\\internet\\AppData\\Local",
                       "\\Programs\\Python\\Python312\\python.exe")
} else {
  
  python_path = paste0("C:\\Users\\Home\\AppData\\Local",
                       "\\Programs\\Python\\Python312\\python.exe")
}

reticulate::use_python(python_path)

```

```{python}

import pandas as pd
import matplotlib.pyplot as plt
import os 

```

In this section, we provide a brief demonstration of a forecasting problem where we compare the performance of two models, a Linear Regression model and a Random Forest Regressor, along with a naive benchmark model. The naive model uses the last known value as the forecast for the next time step. This demonstration focuses on predicting air quality (specifically CO sensor data) based on historical features. The purpose of this exercise is to showcase how different models perform in terms of forecast accuracy, evaluated using Root Mean Squared Error (RMSE), a common metric for assessing regression models.

## Data loading

We start by loading a preprocessed dataset that has already undergone feature engineering. The dataset contains time series data related to air quality, indexed by date and time. The file is loaded as a Pandas DataFrame and is indexed with the `Date_Time` column.

```{python import_data}

file_path = os.path.expanduser("~/Documents") + "\\DS_advanced_website" + \
"\\data\\air_quality_processed_df.csv"

air_quality_processed_df = pd.read_csv(file_path,
                             index_col = "Date_Time")

air_quality_processed_df.index = pd.to_datetime(air_quality_processed_df.index)

```

## Compare models

Next, we split the dataset into training and testing sets. The training set contains data up to a specific cutoff date (`2005-03-04`), and the testing set contains data after that date. The target variable (the one we aim to predict) is `CO_sensor`, which measures the concentration of carbon monoxide detected by the sensor. The feature matrix `X_mat` contains all the other predictor variables.

```{python split_data}

y_vec = air_quality_processed_df["CO_sensor"]

X_mat = air_quality_processed_df.drop("CO_sensor", axis = 1)

X_mat_train = X_mat.loc[X_mat.index <= pd.to_datetime("2005-03-04")]

y_vec_train = y_vec.loc[X_mat.index <= pd.to_datetime("2005-03-04")]

X_mat_test = X_mat.loc[X_mat.index > pd.to_datetime("2005-03-04")]

y_vec_test = y_vec.loc[X_mat.index > pd.to_datetime("2005-03-04")]

```

### Naive model

The naive model is often used as a simple benchmark in forecasting problems. It assumes that the best prediction for the next time step is simply the last observed value from the previous time step. In this case, we use the CO sensor data from the previous hour (`CO_sensor_lag_1`) as our naive forecast.

```{python, naive_forecast}

naive_forecast = air_quality_processed_df.loc[air_quality_processed_df.index > pd.to_datetime("2005-03-04")]["CO_sensor_lag_1"]

```

### Linear regression

The first machine learning model we use is Linear Regression. This model attempts to find a linear relationship between the predictor variables and the target variable. Once trained on the training dataset, we use it to make predictions on the test set.

```{python linear_reg_forecast}

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()

lin_reg.fit(X_mat_train, y_vec_train)

lin_reg_forecast = lin_reg.predict(X_mat_test)

```

### Random forest

The second model is a Random Forest Regressor, an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and avoid overfitting. In this case, we set the number of trees (`n_estimators`) to 50 and the maximum depth of each tree to 3.

```{python random_forest_forecast}

from sklearn.ensemble import RandomForestRegressor

rand_forest = RandomForestRegressor(
    n_estimators=50,
    max_depth=3,
    random_state=0,
)

rand_forest.fit(X_mat_train, y_vec_train)

rand_forest_forecast = rand_forest.predict(X_mat_test)

```

### Evaluate models

To evaluate the performance of the models, we calculate the Root Mean Squared Error (RMSE) for each forecast. RMSE is a widely used metric in forecasting problems because it provides a measure of how well a model's predictions match the actual values, with lower values indicating better performance.

```{python }

from sklearn.metrics import mean_squared_error
import numpy as np

def root_mean_squared_error(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

print(f"Naive forecast error is {root_mean_squared_error(naive_forecast, y_vec_test)}")

print(f"Linear regression error is {root_mean_squared_error(lin_reg_forecast, y_vec_test)}")

print(f"Random forest error is {root_mean_squared_error(rand_forest_forecast, y_vec_test)}")

```

In summary, this demonstration illustrates how different models can be applied to a time series forecasting problem. By comparing a naive model, a linear regression model, and a random forest model, we can observe the strengths and weaknesses of each approach in terms of their forecasting accuracy, as measured by RMSE.
