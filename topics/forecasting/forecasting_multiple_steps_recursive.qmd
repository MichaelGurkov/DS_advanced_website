---
title: "Forecasting multiple periods (steps) ahead - recursive approach"
---
## Introduction

In this tutorial, we will explore how to forecast multiple periods ahead using a recursive approach for time series data. The recursive approach involves forecasting one step at a time: after predicting the next step, we update the input data to reflect this new forecast before predicting the following step. This method is particularly useful for time series forecasting tasks where we aim to predict several future steps based on historical data. We will walk through the entire process, from feature engineering and model training to the recursive forecasting method, utilizing a practical dataset related to air quality measurements.

```{r set_up_python, echo=FALSE}
#|echo: FALSE

if (Sys.getenv("USERPROFILE") == "C:\\Users\\internet"){
  
  python_path = paste0("C:\\Users\\internet\\AppData\\Local",
                       "\\Programs\\Python\\Python312\\python.exe")
} else {
  
  python_path = paste0("C:\\Users\\Home\\AppData\\Local",
                       "\\Programs\\Python\\Python312\\python.exe")
}

reticulate::use_python(python_path)

```

```{python import_libraries}

import numpy as np

import pandas as pd

from feature_engine.creation import CyclicalFeatures

from feature_engine.datetime import DatetimeFeatures

from feature_engine.imputation import DropMissingData

from feature_engine.selection import DropFeatures 

from feature_engine.timeseries.forecasting import (LagFeatures, WindowFeatures)

from sklearn.linear_model import Lasso

from sklearn.multioutput import MultiOutputRegressor

from sklearn.metrics import root_mean_squared_error

from sklearn.pipeline import Pipeline

from sklearn.base import clone

import matplotlib.pyplot as plt

import os 

```

The recursive approach in time series forecasting predicts each step sequentially, updating the input data with each new forecast before proceeding to the next. The idea is to first make a prediction for the next time step based on historical data, then append the predicted value to the input features. This updated data is used to forecast the subsequent time step, and the process repeats for the desired number of forecast periods.

```{python import_data}

file_path = os.path.expanduser("~/Documents") + "\\DS_advanced_website\\data\\example_air_quality.csv"

raw_df = pd.read_csv(file_path,
                             index_col = "Date_Time")

raw_df.index = pd.to_datetime(raw_df.index)

```

## Pipeline

The feature engineering process is key in preparing time series data for forecasting. Here, we will extract important features from the datetime index, such as month, day, and hour. We'll also generate lag features (i.e., previous values from certain intervals) and rolling window features (i.e., averages or other statistics over a specific time window). Additionally, cyclical features like month and hour will be transformed using sine and cosine functions to capture the seasonality and periodic nature of the data. Missing data will be handled, and irrelevant features will be dropped to ensure cleaner inputs for the forecasting model.

```{python define_preprocessing}

date_time_feat = DatetimeFeatures(
  variables = "index",
  features_to_extract = ["month","week","day_of_week",
                         "day_of_month","hour","weekend"]
                         )

lag_feat = LagFeatures(
  variables = ["CO_sensor","RH"],
  freq = ["1h","12h"],
  missing_values = "ignore"
)


window_feat = WindowFeatures(
  variables = ["CO_sensor","RH"],
  window = "3h",
  freq = "1h",
  missing_values = "ignore"
)


cyclical_feat = CyclicalFeatures(
  variables = ["month","hour"],
  drop_original = False
)


na_drop = DropMissingData()

drop_feat = DropFeatures(features_to_drop = ["CO_sensor","RH"])


trans_pipe = Pipeline(
  [("date_time_features",date_time_feat),
   ("lag_features",lag_feat),
   ("window_features",window_feat),
   ("periodic_features",cyclical_feat),
   ("drop_original_features",drop_feat),
   ("drop_missing_values",na_drop)
  ]
  
)


```

The transformations inside the pipeline help to automate the process of preparing the data consistently for both training and prediction. This approach ensures that we can avoid data leakage (i.e., using information from the future) and apply the same set of transformations to any new data points that come in.

```{python pipeline}

trans_pipe = Pipeline(
  
  [
    ("date_time_features",date_time_feat),
    ("lag_features",lag_feat),
    ("window_features",window_feat),
    ("periodic_features",cyclical_feat),
    ("drop_original_features",drop_feat),
    ("drop_missing_values",na_drop)
  ]
  
)

del date_time_feat, lag_feat, window_feat, cyclical_feat, drop_feat,na_drop

```

## Train and Test Split

In time series forecasting, it’s essential to split the data into training and test sets in a way that prevents any future information from contaminating the training set. We will split the dataset so that the test set contains data starting from "2005-03-04,". The test set will be used for model evaluation, while the model will be trained on data before the split point.

```{python split_train_test}

split_point = pd.Timestamp("2005-03-04")

X_train = raw_df.loc[raw_df.index < split_point]

X_test = raw_df.loc[raw_df.index >= split_point]

Y_train = raw_df.loc[raw_df.index < split_point,["CO_sensor", "RH"]]

Y_test = raw_df.loc[raw_df.index >= split_point,["CO_sensor", "RH"]]


```


# Manual Prediction

To illustrate the recursive approach, we will first manually predict the first two forecasting points. This step-by-step process demonstrates how we update the input data with each prediction before using it to forecast the next point. After that, we'll automate the recursive forecasting for subsequent steps.


## Preprocess Data

```{python preprocess_data}

trans_pipe.fit(X_train.copy())

X_train_processed = trans_pipe.transform(X_train.copy())

Y_train_processed = Y_train.loc[X_train_processed.index].copy()

# X_test_processed = trans_pipe.fit_transform(X_test.copy())
# 
# Y_test = Y_test.loc[X_test_processed.index]

```

Once the data is preprocessed and aligned correctly with the target variables, we can move on to training the model. For this, we use Lasso regression, a form of linear regression that includes a regularization term to reduce the complexity of the model and prevent overfitting. It’s well-suited for scenarios where the dataset has many features and we want to ensure that the model generalizes well to new data.

## Fit model

```{python fit_model}

lasso_model = MultiOutputRegressor(Lasso())

lasso_model.fit(X_train_processed, Y_train_processed)

```

### First point

We first manually prepare the input data for the initial forecast point ("2005-03-04 00:00:00"). The input data must include all the necessary features from the previous 12 hours to compute lagged features for this forecast point. After preparing the data, we make the first prediction.

```{python make_input_data_for_first_point}

first_forecast_point = split_point

feature_source_data = X_train.iloc[-12:].copy()
                        
forecast_index_row = pd.DataFrame(data = np.nan,
                            index = [first_forecast_point],
                            columns = ["CO_sensor","RH"])
                            
feature_source_data = pd.concat([feature_source_data.copy(),
                              forecast_index_row], axis = 0)

print(feature_source_data)


```

```{python first_point_process_and_predict}

first_features_vec = trans_pipe.transform(feature_source_data)

first_point_pred = lasso_model.predict(first_features_vec)

predictions_df = pd.DataFrame(data = first_point_pred,
                                index = [first_forecast_point],
                                columns = ["CO_sensor","RH"])
print(predictions_df)

```

### Second point

Next, we update the input data by incorporating the forecast made for the first point and use it to predict the second forecast point.

```{python predict_second_point}

second_forecast_point = first_forecast_point + pd.offsets.Hour(1)

# Update feature source data (exclude the first observation and append forecast)

feature_source_data = feature_source_data.iloc[1:].copy()

feature_source_data.loc[first_forecast_point] = first_point_pred

second_forecast_row = pd.DataFrame(data = np.nan,
                            index = [second_forecast_point],
                            columns = ["CO_sensor","RH"])

feature_source_data = pd.concat([feature_source_data.copy(),
                              second_forecast_row], axis = 0)                      

```

```{python second_point_process_and_predict}

second_features_vec = trans_pipe.transform(feature_source_data)

second_point_pred = lasso_model.predict(second_features_vec)

predictions_df = pd.concat([predictions_df.copy(),
                            pd.DataFrame(data = second_point_pred,
                            index = [second_forecast_point],
                            columns = ["CO_sensor","RH"])])

print(predictions_df)


```

# Automate Recursive Forecast

The recursive approach is automated using a loop. We start by manually making the first forecast and then loop through the remaining forecast horizon, updating the input data and producing the next prediction in each iteration. This modular approach breaks down the forecasting task into two key functions: one for generating the next forecast and another for updating the input data with the latest forecast. We use these functions inside a loop to predict for all remaining time points in the forecast horizon.

```{python auxilary_functions}


def make_recursive_forecast(forecast_horizon,X_train, Y_train,
                            model, preprocess_pipe):
    
    # Preprocess data and fit model
    
    feature_source_data, model_spec,preprocess_pipe_spec = \
    preprocess_data_and_fit_model(X_mat = X_train.copy(),
                    Y_mat = Y_train.copy(),
                    model_spec = model),
                    preprocess_pipe_spec = preprocess_pipe)
                    
    
     
                    
    # Make next prediction
    
    next_pred = predict_next_point(feature_source_data = feature_source_data,
                              model_spec = model_spec,
                              preprocess_pipe_spec = preprocess_pipe_spec)
                              
    predictions_df = next_pred.copy()                          
    
    # Update feature_source_data and iterate
    
    for step in range(1, forecast_horizon):
    
      feature_source_data = pd.concat([feature_source_data.copy(),
                                       next_pred], axis = 0)
                                       
      next_pred = predict_next_point(feature_source_data = feature_source_data,
                                model_spec = model_spec,
                                preprocess_pipe_spec = preprocess_pipe_spec)
                                
      predictions_df = pd.concat([predictions_df.copy(), next_pred],
                                  axis = 0)
                                  
    
    return predictions_df
    
    
 
def preprocess_data_and_fit_model(X_mat, Y_mat,preprocess_pipe_spec, model_spec):
  
  preprocess_pipe_spec.fit(X_mat.copy())
  
  X_mat_processed = preprocess_pipe_spec.transform(X_mat.copy())

  Y_mat_processed = Y_mat.loc[X_mat_processed.index].copy()
  
  model_spec.fit(X_mat_processed,Y_mat_processed)
  
  feature_source_data = X_mat.iloc[-12:]
  
  return([feature_source_data, model_spec,preprocess_pipe_spec])


def predict_next_point(feature_source_data,model_spec,preprocess_pipe_spec):
  
  forecast_index = feature_source_data.index.max() + pd.DateOffset(hours = 1)
  
  forecast_index_row = pd.DataFrame(data = np.nan,
                              index = [forecast_index],
                              columns = ["CO_sensor","RH"])
                              
  feature_source_data = pd.concat([feature_source_data.copy(),
                                forecast_index_row], axis = 0)
                                
  feature_vec = preprocess_pipe_spec.transform(feature_source_data)
  
  feature_vec = feature_vec.iloc[[len(feature_vec) - 1]].copy()
  
  predictions = model_spec.predict(feature_vec)
  
  predictions_df = pd.DataFrame(data = predictions,
                              index = [forecast_index],
                              columns = ["CO_sensor","RH"])
  
  return predictions_df


```

```{python make_predictions}


predictions_for_24_h = make_recursive_forecast(forecast_horizon = 24,
                                               X_train = X_train.copy(),
                                               Y_train = Y_train.copy(),
                                               model = MultiOutputRegressor(Lasso()),
                                               preprocess_pipe = clone(trans_pipe))
                               
print(predictions_for_24_h.head())


```


```{python plot_predictions}

predictions_for_24_h["CO_sensor"].plot()

plt.show()

```

```{python test_for_equality}

print(f"Manual predictions are equal to automatic predicitons: {predictions_df.equals(predictions_for_24_h.iloc[0:2])}")


```



## Summary

In this tutorial, we demonstrated how to use a recursive approach to forecast multiple periods ahead in time series data. By applying a pipeline for feature engineering and using Lasso regression, we built a model to predict air quality sensor readings. The recursive method allowed us to forecast step-by-step, updating the input data with each new prediction. Finally, we automated the process using a loop, making it easy to predict several steps ahead efficiently. This approach is highly adaptable to various time series forecasting problems.