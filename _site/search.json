[
  {
    "objectID": "topics/time_series_decomposition.html",
    "href": "topics/time_series_decomposition.html",
    "title": "Time series decomposition",
    "section": "",
    "text": "import pandas as pd\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\nimport os\nsales_df = pd.read_csv(os.path.expanduser(\"~/Documents\") + \n\"\\\\DS_advanced_website\\\\data\\\\example_retail_sales.csv\")\n\nsales_df[\"date\"] = pd.to_datetime(sales_df[\"date\"], format = \"%m/%d/%Y\")\n\nsales_df[\"sales\"] = sales_df[\"sales\"] / 1000\nplt.figure(figsize=(10, 4))\n\nsns.lineplot(x=\"date\", y=\"sales\",marker = \".\", data=sales_df)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "topics/time_series_decomposition.html#trend",
    "href": "topics/time_series_decomposition.html#trend",
    "title": "Time series decomposition",
    "section": "Trend",
    "text": "Trend\n\nMoving averages\n\n\n# Auxiliary functions\n\ndef plot_combined_trend_and_series(data,**kwargs):\n    # Create a plot with two line plots\n    ax = sns.lineplot(x='date', y='sales', data=data, color=\"lightgray\")\n    \n    sns.lineplot(x='date', y='ma_value', data=data, color=\"steelblue\", ax=ax)\n    \n    return ax\n\ndef plot_panel(wide_df):\n  \n  long_df = wide_df.melt(id_vars=['date', 'sales'],\n                         var_name='ma_type',\n                         value_name='ma_value')\n                         \n  panel_grid = sns.FacetGrid(long_df, col=\"ma_type\",\n                             col_wrap=2,height = 5,aspect = 1.5)\n                             \n  panel_grid.map_dataframe(plot_combined_trend_and_series)\n  \n  plt.show()\n\n\nodd_ma_df = sales_df.copy()\n\nfor win_len in [3,5,7,9]:\n  temp_name = f\"ma_{win_len}\"\n  odd_ma_df[temp_name] = odd_ma_df[\"sales\"].rolling(window = win_len,\n                                                    center = True).mean()\n                                                    \nplot_panel(odd_ma_df)\n\n\n\n\n\n\n\n\n\neven_ma_df = sales_df.copy()\n\nfor win_len in [4,6,8,12]:\n  temp_name = f\"ma_{win_len}\"\n  even_ma_df[temp_name] = even_ma_df[\"sales\"].rolling(window = win_len).mean()\n  even_ma_df[temp_name] = even_ma_df[temp_name].rolling(window = 2).mean()\n  even_ma_df[temp_name] = even_ma_df[temp_name].shift(-win_len//2)\n  \nplot_panel(even_ma_df)\n\n\n\n\n\n\n\n\nImportant - add an explanation of odd ma (pandas give correct result) and even ma (pandas give incorrect result, need to apply another 2 MA and center)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DS_advanced_website",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "topics/tabularizing_time_series/ts_to_table.html",
    "href": "topics/tabularizing_time_series/ts_to_table.html",
    "title": "Tabularizing time series data",
    "section": "",
    "text": "import pandas as pd\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\nimport os \n\n\n\nmulti_items_df = pd.read_csv(os.path.expanduser(\"~/Documents\") + \n\"\\\\DS_advanced_website\\\\data\\\\multi_item_sales.csv\")\n\nmulti_items_df[\"date\"] = pd.to_datetime(multi_items_df[\"date\"],\n                                        format = \"%d/%m/%Y\")\n\n\n\n# Auxiliary functions\n\ndef plot_series(data,**kwargs):\n    # Create a plot with two line plots\n    ax = sns.lineplot(x='date', y='sales', data=data)\n    \n    return ax\n\ndef plot_panel(long_df):\n  \n  panel_grid = sns.FacetGrid(long_df, col=\"item_category\",\n                             col_wrap=1,height = 2, aspect = 3)\n                             \n  panel_grid.map_dataframe(plot_series)\n  \n  plt.show()\n\n\nIntro to timeseries\n\nDefinition and example\nUnivariate and multivariate time series\nMultiple time series\nRegular vs irregular time series\nStationary vs non-stationary\n\nTime series data format has (at least) two mandatory components: 1. The data - a column of values 2. The time index - an additional column or (more commonly) as index of the pandas Series or Data Frame\n++ explain wide format (in this example a date column and 4 columns one for sales of each item: ‘beverages’, ‘bakery’, ‘cleaning’, ‘dairy’ )\n\nmulti_items_df.head()\n\n        date  beverages   bakery  cleaning  dairy\n0 2015-01-02        794  285.628       501    426\n1 2015-01-03        938  289.563       470    568\n2 2015-01-04        574  151.744       312    362\n3 2015-01-05       1299  457.543      1047    814\n4 2015-01-06       1028  405.280       831    679\n\n# Create a figure and axis\nfig, axes = plt.subplots(nrows=4, ncols=1, figsize=(12, 8), sharex=True)\n\n# Plot each series against the date\nfor temp_ind in range(1,multi_items_df.shape[1]):\n  \n  temp_col = multi_items_df.columns.values[temp_ind]\n  \n  multi_items_df.plot(x='date', y=temp_col,ax=axes[temp_ind-1],\n                      title=temp_col.title(), legend = False)\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n++ explain long format (in this example a date column, an item category column and a sales values column)\n\nlong_format = multi_items_df.melt(id_vars = \"date\",\n                                  value_vars = ['beverages', 'bakery',\n                                                'cleaning', 'dairy'],\n                                  var_name = \"item_category\",\n                                  value_name = \"sales\").copy()\n\nlong_format.head()\n\n        date item_category   sales\n0 2015-01-02     beverages   794.0\n1 2015-01-03     beverages   938.0\n2 2015-01-04     beverages   574.0\n3 2015-01-05     beverages  1299.0\n4 2015-01-06     beverages  1028.0\n\n\n\nplot_panel(long_format)"
  },
  {
    "objectID": "topics/time_series_decomposition.html#seasonality",
    "href": "topics/time_series_decomposition.html#seasonality",
    "title": "Time series decomposition",
    "section": "Seasonality",
    "text": "Seasonality"
  },
  {
    "objectID": "topics/tabularizing_time_series/forecasting_demo.html",
    "href": "topics/tabularizing_time_series/forecasting_demo.html",
    "title": "Forecasting demonstration - EDA",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport os"
  },
  {
    "objectID": "topics/tabularizing_time_series/forecasting_demo.html#seasonality",
    "href": "topics/tabularizing_time_series/forecasting_demo.html#seasonality",
    "title": "Forecasting demonstration - EDA",
    "section": "Seasonality",
    "text": "Seasonality\nSeasonality refers to recurring patterns or cycles in data that occur at regular intervals, such as daily or yearly trends. By grouping the data by time of day (i.e., the hour) and averaging across all observations for that time, we can observe how pollutant concentrations (like CO_sensor) vary over the course of a typical day. This allows us to detect intra-day seasonality, which is particularly relevant for environmental and pollution data that may exhibit daily cycles due to human activity or environmental factors.\n\nhours_con = impute_df.groupby(impute_df.index.time)[\n  \"CO_sensor\"].mean().reset_index()\n\nhours_con.plot(x = 'index', y = 'CO_sensor', legend = False)\nplt.title(\"Pollutant concentration over day time\")\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.show()"
  },
  {
    "objectID": "topics/tabularizing_time_series/forecasting_demo_updated.html",
    "href": "topics/tabularizing_time_series/forecasting_demo_updated.html",
    "title": "Forecasting demonstration",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport os"
  },
  {
    "objectID": "topics/tabularizing_time_series/forecasting_demo_updated.html#missing-values-handling",
    "href": "topics/tabularizing_time_series/forecasting_demo_updated.html#missing-values-handling",
    "title": "Forecasting demonstration",
    "section": "Missing values handling",
    "text": "Missing values handling\nTo handle missing data in a time series, we first ensure that our data is uniformly spaced by converting the Date_Time index to an hourly frequency using the .asfreq(\"1h\") method. This step introduces explicit gaps for any missing data points, making them easier to detect. This is important in time series analysis because irregular time steps can mislead algorithms, and most forecasting models require data to be at regular intervals.\n\n\nimpute_df = air_quality_df.asfreq(\"1h\").copy()\n\nfor temp_col in impute_df.columns:\n  impute_df[temp_col + \"_imputed\"] = impute_df[temp_col]\n  impute_df[temp_col + \"_imputed\"] = impute_df[temp_col + \"_imputed\"].ffill()\n\nIn this block, we handle missing values by forward-filling the gaps (.ffill()), which propagates the last observed value forward until a new valid observation is encountered. This is a common imputation technique for time series data, especially in scenarios where missing values are sparse or values don’t drastically change within short time frames.\nWe create new columns (e.g., CO_sensor_imputed, RH_imputed) that store the imputed data, while retaining the original columns for comparison and visualization of the missing values.\nNext, we will overlay the imputed values onto the original time series to visually highlight where data was missing and how it was filled.\n\nfor temp_col in [\"CO_sensor\",\"RH\"]:\n  \n  ax = impute_df[temp_col].plot(figsize = (20,6))\n  \n  impute_df[impute_df[temp_col].isnull()][temp_col + \"_imputed\"].plot(\n    ax = ax,legend = False,marker = \".\", color = \"red\", linestyle='None')\n    \n  plt.title(temp_col, fontsize=20)  # Increase the title font size\n  \n  plt.tick_params(axis='both', which='major', labelsize=16)\n  \n  plt.xlabel('')  # Disable x-axis label\n  \n  plt.ylabel('')  # Disable y-axis label\n  \n  plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe purpose of this code block is to visualize the missing data points and the corresponding imputed values. The original data is plotted as a line, and any missing data points that were imputed are marked with red dots. This method of visual comparison allows us to easily inspect where the forward fill occurred and ensures that the imputation technique was applied correctly without distorting the overall time series pattern."
  },
  {
    "objectID": "topics/tabularizing_time_series/forecasting_demo_updated.html#seasonality",
    "href": "topics/tabularizing_time_series/forecasting_demo_updated.html#seasonality",
    "title": "Forecasting demonstration",
    "section": "Seasonality",
    "text": "Seasonality\nSeasonality refers to recurring patterns or cycles in data that occur at regular intervals, such as daily or yearly trends. By grouping the data by time of day (i.e., the hour) and averaging across all observations for that time, we can observe how pollutant concentrations (like CO_sensor) vary over the course of a typical day. This allows us to detect intra-day seasonality, which is particularly relevant for environmental and pollution data that may exhibit daily cycles due to human activity or environmental factors.\n\nhours_con = impute_df.groupby(impute_df.index.time)[\n  \"CO_sensor\"].mean().reset_index()\n\nhours_con.plot(x = 'index', y = 'CO_sensor', legend = False)\nplt.title(\"Pollutant concentration over day time\")\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.show()"
  },
  {
    "objectID": "topics/tabularizing_time_series/forecasting_demo.html#missing-values-handling",
    "href": "topics/tabularizing_time_series/forecasting_demo.html#missing-values-handling",
    "title": "Forecasting demonstration",
    "section": "Missing values handling",
    "text": "Missing values handling\n++ we’ll highlight the missing values by explicitly converting the frequency of the index to hourly frequency. That will introduce missing points\n\n\nimpute_df = air_quality_df.asfreq(\"1h\").copy()\n\nfor temp_col in impute_df.columns:\n  impute_df[temp_col + \"_imputed\"] = impute_df[temp_col]\n  impute_df[temp_col + \"_imputed\"] = impute_df[temp_col + \"_imputed\"].ffill()\n  \n\n++ explain that we’ll overlay imputed over missing values in order to highlight the missing values present in the data\n\nfor temp_col in [\"CO_sensor\",\"RH\"]:\n  ax = impute_df[temp_col].plot(figsize = (20,6))\n  impute_df[impute_df[temp_col].isnull()][temp_col + \"_imputed\"].plot(ax = ax,\n  legend = False, marker = \".\", color = \"red\", linestyle='None')\n  plt.title(temp_col, fontsize=20)  # Increase the title font size\n  plt.tick_params(axis='both', which='major', labelsize=16)\n  plt.xlabel('')  # Disable x-axis label\n  plt.ylabel('')  # Disable y-axis label\n  plt.show()"
  },
  {
    "objectID": "topics/tabularizing_time_series/forecasting_demo_updated.html#data-loading",
    "href": "topics/tabularizing_time_series/forecasting_demo_updated.html#data-loading",
    "title": "Forecasting demonstration",
    "section": "Data loading",
    "text": "Data loading\n\n\nfile_path = os.path.expanduser(\"~/Documents\") + \"\\\\DS_advanced_website\\\\data\\\\example_air_quality.csv\"\n\nair_quality_df = pd.read_csv(file_path,\n                             index_col = \"Date_Time\")\n\nair_quality_df.index = pd.to_datetime(air_quality_df.index)\n\nThe dataset air_quality_df is loaded from a CSV file and indexed by a column named Date_Time, which represents timestamps of the air quality readings. This timestamp index is essential for time series analysis, allowing us to analyze the data in chronological order. The dataset includes sensor readings such as CO_sensor, which captures the concentration of carbon monoxide (CO) in the air, and RH, which records relative humidity (RH) levels. These two variables provide environmental and pollutant measurements that will be key in our analysis.\n\nfor temp_col in air_quality_df.columns.values:\n  air_quality_df[temp_col].plot(figsize = (20,6))\n  plt.title(temp_col, fontsize=20)  # Increase the title font size\n  plt.tick_params(axis='both', which='major', labelsize=16)\n  plt.xlabel('')  # Disable x-axis label\n  plt.ylabel('')  # Disable y-axis label\n  plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere, we plot each of the columns in the dataset (CO_sensor and RH) to visually explore the time series data. These plots provide a general understanding of how pollutant levels (CO_sensor) and humidity (RH) fluctuate over time. Larger trends, spikes, or patterns such as seasonality may already be visible, and such visualizations are a useful first step before deeper analysis."
  },
  {
    "objectID": "topics/tabularizing_time_series/demo_feature_egineering.html",
    "href": "topics/tabularizing_time_series/demo_feature_egineering.html",
    "title": "Forecasting demonstration - feature engineering",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport os"
  },
  {
    "objectID": "topics/tabularizing_time_series/demo_feature_egineering.html#data-loading",
    "href": "topics/tabularizing_time_series/demo_feature_egineering.html#data-loading",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Data loading",
    "text": "Data loading\n\n\nfile_path = os.path.expanduser(\"~/Documents\") + \"\\\\DS_advanced_website\\\\data\\\\example_air_quality.csv\"\n\nair_quality_df = pd.read_csv(file_path,\n                             index_col = \"Date_Time\")\n\nair_quality_df.index = pd.to_datetime(air_quality_df.index)\n\nThe dataset air_quality_df is loaded from a CSV file and indexed by a column named Date_Time, which represents timestamps of the air quality readings. This timestamp index is essential for time series analysis, allowing us to analyze the data in chronological order. The dataset includes sensor readings such as CO_sensor, which captures the concentration of carbon monoxide (CO) in the air, and RH, which records relative humidity (RH) levels. These two variables provide environmental and pollutant measurements that will be key in our analysis."
  },
  {
    "objectID": "topics/tabularizing_time_series/demo_feature_egineering.html#time-related-features",
    "href": "topics/tabularizing_time_series/demo_feature_egineering.html#time-related-features",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Time related features",
    "text": "Time related features\nIn this section, we extract time-related features that are essential for improving the performance of our forecasting model. These features include temporal information such as the month, day, and hour of each observation. These are known as “future-known” features, meaning that their values for future timestamps are already known at the time of making a forecast. For example, we always know in advance what the month or hour will be for any given future date. These time-related features provide useful context that can help the model better understand seasonal patterns, daily fluctuations, or other time-dependent behaviors in the data.\n\ncalendar_df = pd.DataFrame(index = air_quality_df.index)\n\ncalendar_df[\"Month\"] = air_quality_df.index.month\n\ncalendar_df[\"Day\"] = air_quality_df.index.day\n\ncalendar_df[\"Hour\"] = air_quality_df.index.hour\n\ncalendar_df.head()\n\n                     Month  Day  Hour\nDate_Time                            \n2004-04-04 00:00:00      4    4     0\n2004-04-04 01:00:00      4    4     1\n2004-04-04 02:00:00      4    4     2\n2004-04-04 03:00:00      4    4     3\n2004-04-04 04:00:00      4    4     4"
  },
  {
    "objectID": "topics/tabularizing_time_series/demo_feature_egineering.html#lag-features",
    "href": "topics/tabularizing_time_series/demo_feature_egineering.html#lag-features",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Lag features",
    "text": "Lag features\nLag features capture values from previous time points and can be particularly useful in forecasting. For instance, the concentration of CO at the current hour could be related to the concentration of CO from one or 24 hours ago. By introducing lagged versions of the original features, the model gains insight into how past values may influence future outcomes.\nIn the code, we generate lag features for each variable using a set of lag intervals (1 hour and 24 hours). This is done by shifting the values in the dataset by the specified lag periods. However, this process creates missing values for the initial time steps where the lagged data is not available (e.g., if we’re using a 24-hour lag, the first 24 hours will have missing values). These missing values will need to be handled later by either imputing them or dropping the corresponding rows.\nAdditionally, note the use of parentheses to continue the statement across lines in the loop. This enhances code readability and makes it easier to follow the logic.\n\nlag_features_df = pd.DataFrame(index = air_quality_df.index)\n\nlags = [1, 24]\n\nfor temp_col in air_quality_df.columns:\n  for temp_lag in lags:\n    lag_features_df[temp_col + \"_lag_\" + str(temp_lag)] = (\n      air_quality_df[temp_col].shift(freq = str(temp_lag) + \"h\")\n      )\n\nlag_features_df.head(25)\n\n                     CO_sensor_lag_1  CO_sensor_lag_24  RH_lag_1  RH_lag_24\nDate_Time                                                                  \n2004-04-04 00:00:00              NaN               NaN       NaN        NaN\n2004-04-04 01:00:00           1224.0               NaN      56.5        NaN\n2004-04-04 02:00:00           1215.0               NaN      59.2        NaN\n2004-04-04 03:00:00           1115.0               NaN      62.4        NaN\n2004-04-04 04:00:00           1124.0               NaN      65.0        NaN\n2004-04-04 05:00:00           1028.0               NaN      65.3        NaN\n2004-04-04 06:00:00           1010.0               NaN      66.5        NaN\n2004-04-04 07:00:00           1074.0               NaN      69.1        NaN\n2004-04-04 08:00:00           1034.0               NaN      64.8        NaN\n2004-04-04 09:00:00           1130.0               NaN      59.0        NaN\n2004-04-04 10:00:00           1275.0               NaN      49.8        NaN\n2004-04-04 11:00:00           1324.0               NaN      40.7        NaN\n2004-04-04 12:00:00           1268.0               NaN      37.1        NaN\n2004-04-04 13:00:00           1272.0               NaN      33.8        NaN\n2004-04-04 14:00:00           1160.0               NaN      32.1        NaN\n2004-04-04 15:00:00           1136.0               NaN      31.1        NaN\n2004-04-04 16:00:00           1296.0               NaN      30.8        NaN\n2004-04-04 17:00:00           1345.0               NaN      36.0        NaN\n2004-04-04 18:00:00           1296.0               NaN      36.2        NaN\n2004-04-04 19:00:00           1258.0               NaN      39.3        NaN\n2004-04-04 20:00:00           1420.0               NaN      44.6        NaN\n2004-04-04 21:00:00           1366.0               NaN      48.9        NaN\n2004-04-04 22:00:00           1113.0               NaN      56.1        NaN\n2004-04-04 23:00:00           1196.0               NaN      58.8        NaN\n2004-04-05 00:00:00           1188.0            1224.0      60.8       56.5"
  },
  {
    "objectID": "topics/tabularizing_time_series/forecasting_demo.html#data-loading",
    "href": "topics/tabularizing_time_series/forecasting_demo.html#data-loading",
    "title": "Forecasting demonstration - EDA",
    "section": "Data loading",
    "text": "Data loading\n\n\nfile_path = os.path.expanduser(\"~/Documents\") + \"\\\\DS_advanced_website\\\\data\\\\example_air_quality.csv\"\n\nair_quality_df = pd.read_csv(file_path,\n                             index_col = \"Date_Time\")\n\nair_quality_df.index = pd.to_datetime(air_quality_df.index)\n\nThe dataset air_quality_df is loaded from a CSV file and indexed by a column named Date_Time, which represents timestamps of the air quality readings. This timestamp index is essential for time series analysis, allowing us to analyze the data in chronological order. The dataset includes sensor readings such as CO_sensor, which captures the concentration of carbon monoxide (CO) in the air, and RH, which records relative humidity (RH) levels. These two variables provide environmental and pollutant measurements that will be key in our analysis.\n\nfor temp_col in air_quality_df.columns.values:\n  air_quality_df[temp_col].plot(figsize = (20,6))\n  plt.title(temp_col, fontsize=20)  # Increase the title font size\n  plt.tick_params(axis='both', which='major', labelsize=16)\n  plt.xlabel('')  # Disable x-axis label\n  plt.ylabel('')  # Disable y-axis label\n  plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere, we plot each of the columns in the dataset (CO_sensor and RH) to visually explore the time series data. These plots provide a general understanding of how pollutant levels (CO_sensor) and humidity (RH) fluctuate over time. Larger trends, spikes, or patterns such as seasonality may already be visible, and such visualizations are a useful first step before deeper analysis."
  },
  {
    "objectID": "topics/tabularizing_time_series/forecasting_demo.html#missing-values",
    "href": "topics/tabularizing_time_series/forecasting_demo.html#missing-values",
    "title": "Forecasting demonstration - EDA",
    "section": "Missing values",
    "text": "Missing values\nTo handle missing data in a time series, we first ensure that our data is uniformly spaced by converting the Date_Time index to an hourly frequency using the .asfreq(\"1h\") method. This step introduces explicit gaps for any missing data points, making them easier to detect. This is important in time series analysis because irregular time steps can mislead algorithms, and most forecasting models require data to be at regular intervals.\n\n\nimpute_df = air_quality_df.asfreq(\"1h\").copy()\n\nfor temp_col in impute_df.columns:\n  impute_df[temp_col + \"_imputed\"] = impute_df[temp_col]\n  impute_df[temp_col + \"_imputed\"] = impute_df[temp_col + \"_imputed\"].ffill()\n\nIn this block, we handle missing values by forward-filling the gaps (.ffill()), which propagates the last observed value forward until a new valid observation is encountered. This is a common imputation technique for time series data, especially in scenarios where missing values are sparse or values don’t drastically change within short time frames.\nWe create new columns (e.g., CO_sensor_imputed, RH_imputed) that store the imputed data, while retaining the original columns for comparison and visualization of the missing values.\nNext, we will overlay the imputed values onto the original time series to visually highlight where data was missing and how it was filled.\n\nfor temp_col in [\"CO_sensor\",\"RH\"]:\n  \n  ax = impute_df[temp_col].plot(figsize = (20,6))\n  \n  impute_df[impute_df[temp_col].isnull()][temp_col + \"_imputed\"].plot(\n    ax = ax,legend = False,marker = \".\", color = \"red\", linestyle='None')\n    \n  plt.title(temp_col, fontsize=20)  # Increase the title font size\n  \n  plt.tick_params(axis='both', which='major', labelsize=16)\n  \n  plt.xlabel('')  # Disable x-axis label\n  \n  plt.ylabel('')  # Disable y-axis label\n  \n  plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe purpose of this code block is to visualize the missing data points and the corresponding imputed values. The original data is plotted as a line, and any missing data points that were imputed are marked with red dots. This method of visual comparison allows us to easily inspect where the forward fill occurred and ensures that the imputation technique was applied correctly without distorting the overall time series pattern."
  },
  {
    "objectID": "topics/tabularizing_time_series/demo_feature_egineering.html#window-features",
    "href": "topics/tabularizing_time_series/demo_feature_egineering.html#window-features",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Window features",
    "text": "Window features\nWindow features represent rolling statistics (such as averages) calculated over a fixed window of previous time points. These are useful in capturing short-term trends in the data. For example, the mean CO concentration over the past three or seven hours might provide valuable information for predicting future values.\nIn the code, we generate window features by computing the rolling mean over windows of 3 and 7 hours. The .shift() function is applied to ensure that the calculated window statistics are available only for past observations (i.e., the mean is based on past data up to the current time point). This ensures that the model respects the forecasting principle of only using information that would have been available at the time of prediction.\n\nwindow_features_df = pd.DataFrame(index = air_quality_df.index)\n\nwindows = [3, 7]\n\nfor temp_col in air_quality_df.columns:\n  for temp_win in windows:\n    window_features_df[temp_col + \"_win_\" + str(temp_win)] = (\n      air_quality_df[temp_col]\n      .rolling(window = temp_win).mean()\n      .shift(freq = \"1h\")\n      )\n\nwindow_features_df.head(8)\n\n                     CO_sensor_win_3  CO_sensor_win_7   RH_win_3   RH_win_7\nDate_Time                                                                  \n2004-04-04 00:00:00              NaN              NaN        NaN        NaN\n2004-04-04 01:00:00              NaN              NaN        NaN        NaN\n2004-04-04 02:00:00              NaN              NaN        NaN        NaN\n2004-04-04 03:00:00      1184.666667              NaN  59.366667        NaN\n2004-04-04 04:00:00      1151.333333              NaN  62.200000        NaN\n2004-04-04 05:00:00      1089.000000              NaN  64.233333        NaN\n2004-04-04 06:00:00      1054.000000              NaN  65.600000        NaN\n2004-04-04 07:00:00      1037.333333      1112.857143  66.966667  63.428571\n\n\nLet’s verify the calculation of the 3-hour window feature manually. We want to compute the mean CO concentration for the hours leading up to “2004-04-04 03:00:00” (i.e., using data from “2004-04-04 00:00:00” to “2004-04-04 02:00:00”).\n\nexpected_value = air_quality_df.loc[\n  (air_quality_df.index &gt;= pd.Timestamp(\"2004-04-04 00:00:00\")) &\n  (air_quality_df.index &lt;= pd.Timestamp(\"2004-04-04 02:00:00\"))\n  ][\"CO_sensor\"].mean()\n\nexpected_value = round(expected_value,3)\n\ncalculated_value = window_features_df.loc[\nwindow_features_df.index == pd.Timestamp(\"2004-04-04 03:00:00\")\n][\"CO_sensor_win_3\"].iloc[0]\n\ncalculated_value = round(calculated_value,3)\n\nif (expected_value == calculated_value):\n  print(f'''\n  the expected value is {expected_value}, the calculated value is {calculated_value}. \n  We're good!\n  ''')\n\n\n  the expected value is 1184.667, the calculated value is 1184.667. \n  We're good!"
  },
  {
    "objectID": "topics/tabularizing_time_series/temp.html",
    "href": "topics/tabularizing_time_series/temp.html",
    "title": "Forecasting demonstration - feature engineering",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport os"
  },
  {
    "objectID": "topics/tabularizing_time_series/temp.html#data-loading",
    "href": "topics/tabularizing_time_series/temp.html#data-loading",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Data loading",
    "text": "Data loading\n\n\nfile_path = os.path.expanduser(\"~/Documents\") + \"\\\\DS_advanced_website\\\\data\\\\example_air_quality.csv\"\n\nair_quality_df = pd.read_csv(file_path,\n                             index_col = \"Date_Time\")\n\nair_quality_df.index = pd.to_datetime(air_quality_df.index)\n\nThe dataset air_quality_df is loaded from a CSV file and indexed by a column named Date_Time, which represents timestamps of the air quality readings. This timestamp index is essential for time series analysis, allowing us to analyze the data in chronological order. The dataset includes sensor readings such as CO_sensor, which captures the concentration of carbon monoxide (CO) in the air, and RH, which records relative humidity (RH) levels. These two variables provide environmental and pollutant measurements that will be key in our analysis."
  },
  {
    "objectID": "topics/tabularizing_time_series/temp.html#time-related-features",
    "href": "topics/tabularizing_time_series/temp.html#time-related-features",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Time related features",
    "text": "Time related features\nIn this section, we extract time-related features that are essential for improving the performance of our forecasting model. These features include temporal information such as the month, day, and hour of each observation. These are known as “future-known” features, meaning that their values for future timestamps are already known at the time of making a forecast. For example, we always know in advance what the month or hour will be for any given future date. These time-related features provide useful context that can help the model better understand seasonal patterns, daily fluctuations, or other time-dependent behaviors in the data.\n\ncalendar_df = pd.DataFrame(index = air_quality_df.index)\n\ncalendar_df[\"Month\"] = air_quality_df.index.month\n\ncalendar_df[\"Day\"] = air_quality_df.index.day\n\ncalendar_df[\"Hour\"] = air_quality_df.index.hour\n\ncalendar_df.head()\n\n                     Month  Day  Hour\nDate_Time                            \n2004-04-04 00:00:00      4    4     0\n2004-04-04 01:00:00      4    4     1\n2004-04-04 02:00:00      4    4     2\n2004-04-04 03:00:00      4    4     3\n2004-04-04 04:00:00      4    4     4"
  },
  {
    "objectID": "topics/tabularizing_time_series/temp.html#lag-features",
    "href": "topics/tabularizing_time_series/temp.html#lag-features",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Lag features",
    "text": "Lag features\nLag features capture values from previous time points and can be particularly useful in forecasting. For instance, the concentration of CO at the current hour could be related to the concentration of CO from one or 24 hours ago. By introducing lagged versions of the original features, the model gains insight into how past values may influence future outcomes.\nIn the code, we generate lag features for each variable using a set of lag intervals (1 hour and 24 hours). This is done by shifting the values in the dataset by the specified lag periods. However, this process creates missing values for the initial time steps where the lagged data is not available (e.g., if we’re using a 24-hour lag, the first 24 hours will have missing values). These missing values will need to be handled later by either imputing them or dropping the corresponding rows.\nAdditionally, note the use of parentheses to continue the statement across lines in the loop. This enhances code readability and makes it easier to follow the logic.\n\nlag_features_df = pd.DataFrame(index = air_quality_df.index)\n\nlags = [1, 24]\n\nfor temp_col in air_quality_df.columns:\n  for temp_lag in lags:\n    lag_features_df[temp_col + \"_lag_\" + str(temp_lag)] = (\n      air_quality_df[temp_col].shift(freq = str(temp_lag) + \"h\")\n      )\n\nlag_features_df.head(25)\n\n                     CO_sensor_lag_1  CO_sensor_lag_24  RH_lag_1  RH_lag_24\nDate_Time                                                                  \n2004-04-04 00:00:00              NaN               NaN       NaN        NaN\n2004-04-04 01:00:00           1224.0               NaN      56.5        NaN\n2004-04-04 02:00:00           1215.0               NaN      59.2        NaN\n2004-04-04 03:00:00           1115.0               NaN      62.4        NaN\n2004-04-04 04:00:00           1124.0               NaN      65.0        NaN\n2004-04-04 05:00:00           1028.0               NaN      65.3        NaN\n2004-04-04 06:00:00           1010.0               NaN      66.5        NaN\n2004-04-04 07:00:00           1074.0               NaN      69.1        NaN\n2004-04-04 08:00:00           1034.0               NaN      64.8        NaN\n2004-04-04 09:00:00           1130.0               NaN      59.0        NaN\n2004-04-04 10:00:00           1275.0               NaN      49.8        NaN\n2004-04-04 11:00:00           1324.0               NaN      40.7        NaN\n2004-04-04 12:00:00           1268.0               NaN      37.1        NaN\n2004-04-04 13:00:00           1272.0               NaN      33.8        NaN\n2004-04-04 14:00:00           1160.0               NaN      32.1        NaN\n2004-04-04 15:00:00           1136.0               NaN      31.1        NaN\n2004-04-04 16:00:00           1296.0               NaN      30.8        NaN\n2004-04-04 17:00:00           1345.0               NaN      36.0        NaN\n2004-04-04 18:00:00           1296.0               NaN      36.2        NaN\n2004-04-04 19:00:00           1258.0               NaN      39.3        NaN\n2004-04-04 20:00:00           1420.0               NaN      44.6        NaN\n2004-04-04 21:00:00           1366.0               NaN      48.9        NaN\n2004-04-04 22:00:00           1113.0               NaN      56.1        NaN\n2004-04-04 23:00:00           1196.0               NaN      58.8        NaN\n2004-04-05 00:00:00           1188.0            1224.0      60.8       56.5"
  },
  {
    "objectID": "topics/tabularizing_time_series/temp.html#window-features",
    "href": "topics/tabularizing_time_series/temp.html#window-features",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Window features",
    "text": "Window features\nWindow features represent rolling statistics (such as averages) calculated over a fixed window of previous time points. These are useful in capturing short-term trends in the data. For example, the mean CO concentration over the past three or seven hours might provide valuable information for predicting future values.\nIn the code, we generate window features by computing the rolling mean over windows of 3 and 7 hours. The .shift() function is applied to ensure that the calculated window statistics are available only for past observations (i.e., the mean is based on past data up to the current time point). This ensures that the model respects the forecasting principle of only using information that would have been available at the time of prediction.\n\nwindow_features_df = pd.DataFrame(index = air_quality_df.index)\n\nwindows = [3, 7]\n\nfor temp_col in air_quality_df.columns:\n  for temp_win in windows:\n    window_features_df[temp_col + \"_win_\" + str(temp_win)] = (\n      air_quality_df[temp_col]\n      .rolling(window = temp_win).mean()\n      .shift(freq = \"1h\")\n      )\n\nwindow_features_df.head(8)\n\n                     CO_sensor_win_3  CO_sensor_win_7   RH_win_3   RH_win_7\nDate_Time                                                                  \n2004-04-04 00:00:00              NaN              NaN        NaN        NaN\n2004-04-04 01:00:00              NaN              NaN        NaN        NaN\n2004-04-04 02:00:00              NaN              NaN        NaN        NaN\n2004-04-04 03:00:00      1184.666667              NaN  59.366667        NaN\n2004-04-04 04:00:00      1151.333333              NaN  62.200000        NaN\n2004-04-04 05:00:00      1089.000000              NaN  64.233333        NaN\n2004-04-04 06:00:00      1054.000000              NaN  65.600000        NaN\n2004-04-04 07:00:00      1037.333333      1112.857143  66.966667  63.428571\n\n\nLet’s verify the calculation of the 3-hour window feature manually. We want to compute the mean CO concentration for the hours leading up to “2004-04-04 03:00:00” (i.e., using data from “2004-04-04 00:00:00” to “2004-04-04 02:00:00”).\n\nexpected_value = air_quality_df.loc[\n                                                                                                                 (air_quality_df.index &gt;= pd.Timestamp(\"2004-04-04 00:00:00\")) &\n                                                                                                                 (air_quality_df.index &lt;= pd.Timestamp(\"2004-04-04 02:00:00\"))\n                                                                                                                 ][\"CO_sensor\"].mean()\n\nexpected_value = round(expected_value,3)\n\ncalculated_value = window_features_df.loc[\nwindow_features_df.index == pd.Timestamp(\"2004-04-04 03:00:00\")\n][\"CO_sensor_win_3\"].iloc[0]\n\ncalculated_value = round(calculated_value,3)\n\nif (expected_value == calculated_value):\n  print(f'''\n  the expected value is {expected_value}, the calculated value is {calculated_value}. \n  We're good!\n  ''')\n\n\n  the expected value is 1184.667, the calculated value is 1184.667. \n  We're good!"
  },
  {
    "objectID": "topics/tabularizing_time_series/temp.html#periodic-features",
    "href": "topics/tabularizing_time_series/temp.html#periodic-features",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Periodic features",
    "text": "Periodic features\nCertain time-related features, such as the month or hour, follow a cyclical pattern. For instance, December (month 12) is closer to January (month 1) than it is to April (month 4), even though 12 is numerically farther from 1 than from 4. To capture this cyclical nature, we can transform these features using periodic functions such as sine and cosine.\nBy converting numerical time features into cyclical features, we help the model learn seasonal patterns more effectively. For this purpose, we use the feature_engine library to create these cyclical features for our dataset.\n\nfrom feature_engine.creation import CyclicalFeatures\n\ncyclical = CyclicalFeatures(\n  drop_original = True,\n)\n\ncyclycal_df = cyclical.fit_transform(calendar_df)\n\ncyclycal_df.head()\n\n                     Month_sin  Month_cos  ...  Hour_sin  Hour_cos\nDate_Time                                  ...                    \n2004-04-04 00:00:00   0.866025       -0.5  ...  0.000000  1.000000\n2004-04-04 01:00:00   0.866025       -0.5  ...  0.269797  0.962917\n2004-04-04 02:00:00   0.866025       -0.5  ...  0.519584  0.854419\n2004-04-04 03:00:00   0.866025       -0.5  ...  0.730836  0.682553\n2004-04-04 04:00:00   0.866025       -0.5  ...  0.887885  0.460065\n\n[5 rows x 6 columns]"
  },
  {
    "objectID": "topics/tabularizing_time_series/demo_feature_egineering.html#periodic-features",
    "href": "topics/tabularizing_time_series/demo_feature_egineering.html#periodic-features",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Periodic features",
    "text": "Periodic features\nCertain time-related features, such as the month or hour, follow a cyclical pattern. For instance, December (month 12) is closer to January (month 1) than it is to April (month 4), even though 12 is numerically farther from 1 than from 4. To capture this cyclical nature, we can transform these features using periodic functions such as sine and cosine.\nBy converting numerical time features into cyclical features, we help the model learn seasonal patterns more effectively. For this purpose, we use the feature_engine library to create these cyclical features for our dataset.\n\nfrom feature_engine.creation import CyclicalFeatures\n\ncyclical = CyclicalFeatures(\n  drop_original = True,\n)\n\ncyclical_df = cyclical.fit_transform(calendar_df)\n\ncyclical_df.head()\n\n                     Month_sin  Month_cos  ...  Hour_sin  Hour_cos\nDate_Time                                  ...                    \n2004-04-04 00:00:00   0.866025       -0.5  ...  0.000000  1.000000\n2004-04-04 01:00:00   0.866025       -0.5  ...  0.269797  0.962917\n2004-04-04 02:00:00   0.866025       -0.5  ...  0.519584  0.854419\n2004-04-04 03:00:00   0.866025       -0.5  ...  0.730836  0.682553\n2004-04-04 04:00:00   0.866025       -0.5  ...  0.887885  0.460065\n\n[5 rows x 6 columns]"
  },
  {
    "objectID": "topics/tabularizing_time_series/forecaster_demo.html",
    "href": "topics/tabularizing_time_series/forecaster_demo.html",
    "title": "Forecasting demonstration - EDA",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport os"
  },
  {
    "objectID": "topics/tabularizing_time_series/forecaster_demo.html#data-loading",
    "href": "topics/tabularizing_time_series/forecaster_demo.html#data-loading",
    "title": "Forecasting demonstration - EDA",
    "section": "Data loading",
    "text": "Data loading\n\n\nfile_path = os.path.expanduser(\"~/Documents\") + \"\\\\DS_advanced_website\" + \\\n\"\\\\data\\\\air_quality_processed_df.csv\"\n\nair_quality_processed_df = pd.read_csv(file_path,\n                             index_col = \"Date_Time\")\n\nair_quality_processed_df.index = pd.to_datetime(air_quality_processed_df.index)"
  },
  {
    "objectID": "topics/tabularizing_time_series/forecaster_demo.html#compare-models",
    "href": "topics/tabularizing_time_series/forecaster_demo.html#compare-models",
    "title": "Forecasting demonstration - EDA",
    "section": "Compare models",
    "text": "Compare models\n\n\ny_vec = air_quality_processed_df[\"CO_sensor\"]\n\nX_mat = air_quality_processed_df.drop(\"CO_sensor\", axis = 1)\n\nX_mat_train = X_mat.loc[X_mat.index &lt;= pd.to_datetime(\"2005-03-04\")]\n\ny_vec_train = y_vec.loc[X_mat.index &lt;= pd.to_datetime(\"2005-03-04\")]\n\nX_mat_test = X_mat.loc[X_mat.index &gt; pd.to_datetime(\"2005-03-04\")]\n\ny_vec_test = y_vec.loc[X_mat.index &gt; pd.to_datetime(\"2005-03-04\")]\n\n\nNaive model\n++ explain that as naive model we often take the last known value (the previous hour value in our case)\n\n\nnaive_forecast = air_quality_processed_df.loc[air_quality_processed_df.index &gt; pd.to_datetime(\"2005-03-04\")][\"CO_sensor_lag_1\"]\n\n\n\nLinear regression\n\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\n\nlin_reg.fit(X_mat_train, y_vec_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression() \n\n\nlin_reg_forecast = lin_reg.predict(X_mat_test)\n\n\n\nRandom forest\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrand_forest = RandomForestRegressor(\n    n_estimators=50,\n    max_depth=3,\n    random_state=0,\n)\n\nrand_forest.fit(X_mat_train, y_vec_train)\n\nRandomForestRegressor(max_depth=3, n_estimators=50, random_state=0)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestRegressor?Documentation for RandomForestRegressoriFittedRandomForestRegressor(max_depth=3, n_estimators=50, random_state=0) \n\n\nrand_forest_forecast = lin_reg.predict(X_mat_test)\n\n\n\nEvaluate models\n\nfrom sklearn.metrics import root_mean_squared_error\n\n\nprint(f\"Naive forecat error is {root_mean_squared_error(naive_forecast, y_vec_test)}\")\n\nNaive forecat error is 104.08288851736968\n\nprint(f\"Linear regression error is {root_mean_squared_error(lin_reg_forecast, y_vec_test)}\")\n\nLinear regression error is 86.8976149413457\n\nprint(f\"Random forest error is {root_mean_squared_error(rand_forest_forecast, y_vec_test)}\")\n\nRandom forest error is 86.8976149413457"
  },
  {
    "objectID": "topics/tabularizing_time_series/demo_feature_egineering.html#save-processed-data",
    "href": "topics/tabularizing_time_series/demo_feature_egineering.html#save-processed-data",
    "title": "Forecasting demonstration - feature engineering",
    "section": "Save processed data",
    "text": "Save processed data\n\n\nprocessed_df = pd.concat([air_quality_df, calendar_df,lag_features_df, cyclical_df], axis = 1)\n\nprocessed_df.to_csv(os.path.expanduser(\"~/Documents\") + \"\\\\DS_advanced_website\" + \"\\\\data\\\\air_quality_processed_df.csv\")"
  }
]