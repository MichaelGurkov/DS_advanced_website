[
  {
    "objectID": "topics/intro/forecaster_demo.html",
    "href": "topics/intro/forecaster_demo.html",
    "title": "Forecasting demonstration",
    "section": "",
    "text": "import pandas as pd\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nimport os \n\nfrom feature_engine.timeseries.forecasting import LagFeatures\n\nfrom feature_engine.imputation import DropMissingData\n\nfrom feature_engine.selection import DropFeatures \n\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.metrics import root_mean_squared_error\nIn this section, we provide a brief demonstration of a forecasting problem using a simple Linear Regression model. The dataset used for this example consists of historical airline passenger numbers. Our goal is to demonstrate the forecasting process, including key steps such as feature engineering, model fitting, and forecast evaluation."
  },
  {
    "objectID": "topics/intro/forecaster_demo.html#data-loading",
    "href": "topics/intro/forecaster_demo.html#data-loading",
    "title": "Forecasting demonstration",
    "section": "Data loading",
    "text": "Data loading\nThe dataset contains monthly data on the number of airline passengers from January 1949 to December 1960. This time series dataset is commonly used in forecasting examples due to its clear seasonal patterns and upward trend over time. The time index of the data represents the first day of each month, and the target variable is the number of passengers. The following code loads the dataset, ensures the date column is correctly parsed as a datetime object, and sets it as the index of the DataFrame.\n\n\nfile_path = os.path.expanduser(\"~/Documents\") + \"\\\\DS_advanced_website\\\\data\\\\example_air_passengers.csv\"\n\nraw_df = pd.read_csv(file_path,index_col = \"date\")\n\nraw_df.index = pd.to_datetime(raw_df.index)"
  },
  {
    "objectID": "topics/intro/forecaster_demo.html#performance-evaluation",
    "href": "topics/intro/forecaster_demo.html#performance-evaluation",
    "title": "Forecasting demonstration",
    "section": "Performance evaluation",
    "text": "Performance evaluation\nTo evaluate the model’s performance, we calculate the Root Mean Squared Error (RMSE), a commonly used metric in forecasting. RMSE measures the average magnitude of the prediction errors, with lower values indicating a better fit between the predicted and actual values. By comparing the RMSE for both the training and test sets, we can gauge how well the model performs and whether it generalizes effectively to new data.\n\nprint(f\"Train set RMSE is {np.round(root_mean_squared_error(y_train, y_train_pred),2)}\")\n\nTrain set RMSE is 23.22\n\nprint(f\"Test set RMSE is {np.round(root_mean_squared_error(y_test, y_test_pred),2)}\")\n\nTest set RMSE is 49.64"
  },
  {
    "objectID": "topics/intro/forecaster_demo.html#summary",
    "href": "topics/intro/forecaster_demo.html#summary",
    "title": "Forecasting demonstration",
    "section": "Summary",
    "text": "Summary\nIn this demonstration, we explored the basic steps of a time series forecasting task using airline passenger data. We processed the data by creating lagged features, trained a simple Linear Regression model, and evaluated the model’s performance using RMSE. This step-by-step approach shows how to handle feature engineering, model training, and performance evaluation in a forecasting scenario, providing a foundation for more advanced time series techniques."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DS_advanced_website",
    "section": "",
    "text": "Forecast Demo\n\n\n\n\n \n\nDirect forecast"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "topics/intro/direct_forecasting.html",
    "href": "topics/intro/direct_forecasting.html",
    "title": "Forecasting Interval (Multiple Periods Ahead) - Direct Approach",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nfrom feature_engine.imputation import DropMissingData\nfrom feature_engine.selection import DropFeatures \nfrom feature_engine.timeseries.forecasting import LagFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.metrics import root_mean_squared_error\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.pyplot as plt\nimport os\nIn this tutorial, we will demonstrate a method for forecasting multiple periods ahead using a pipeline-based approach in Python. Specifically, we will use a direct approach for multi-step forecasting, where each future period within the forecast horizon is predicted independently. The direct approach allows us to generate a forecast for each individual time point in a given interval, which is helpful for applications that need predictions for multiple consecutive periods. For our demonstration, we’ll use a forecast interval of three periods, predicting the next, the following, and the third subsequent time point. This approach involves handling the challenges of preparing lagged data and synchronizing multiple targets across different forecast horizons.\nfile_path = os.path.expanduser(\"~/Documents\") + \"\\\\DS_advanced_website\\\\data\\\\example_air_passengers.csv\"\n\nraw_df = pd.read_csv(file_path,index_col = \"date\")\n\nraw_df.index = pd.to_datetime(raw_df.index)"
  },
  {
    "objectID": "topics/intro/direct_forecasting.html#performance-evaluation",
    "href": "topics/intro/direct_forecasting.html#performance-evaluation",
    "title": "Forecasting Interval (Multiple Periods Ahead) - Direct Approach",
    "section": "Performance evaluation",
    "text": "Performance evaluation\nTo evaluate the model’s performance, we calculate the Root Mean Squared Error (RMSE), a commonly used metric in forecasting. RMSE measures the average magnitude of the prediction errors, with lower values indicating a better fit between the predicted and actual values. By comparing the RMSE for both the training and test sets, we can gauge how well the model performs and whether it generalizes effectively to new data.\n\nfor temp_h in range(forecast_horizon):\n  \n  y_pred_train = Y_train_pred[[f\"pred_{temp_h}\"]]\n  \n  y_actual_train = Y_train_processed[f\"h_{temp_h}\"]\n  \n  train_rmse = root_mean_squared_error(y_pred_train, y_actual_train)\n  \n  y_pred_test = Y_test_pred[[f\"pred_{temp_h}\"]]\n  \n  y_actual_test = Y_test_processed[f\"h_{temp_h}\"]\n  \n  test_rmse = root_mean_squared_error(y_pred_test, y_actual_test)\n  \n  print(f\"Train RMSE for horizon {temp_h} is {np.round(train_rmse,2)}, Test RMSE is {np.round(test_rmse,2)}\")\n\nTrain RMSE for horizon 0 is 22.73, Test RMSE is 49.69\nTrain RMSE for horizon 1 is 35.5, Test RMSE is 81.48\nTrain RMSE for horizon 2 is 42.48, Test RMSE is 99.33"
  }
]